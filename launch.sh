#!/bin/bash
set -e

# ======= é…ç½®åŒºåŸŸ =======
GITHUB_USERNAME="Johnny-dai-git"
GITHUB_TOKEN="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"
GITHUB_REPO="llm-deployment"
GITHUB_BRANCH="main"
GITHUB_URL="https://${GITHUB_TOKEN}@github.com/${GITHUB_USERNAME}/${GITHUB_REPO}.git"

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPO_DIR="${SCRIPT_DIR}"
INSTALL_DIR="${REPO_DIR}/install"
CONTROL_DIR="${REPO_DIR}/control"

echo "===== æœ¬åœ° system èŠ‚ç‚¹å®Œæ•´åˆå§‹åŒ–å¼€å§‹ï¼ˆcontrol planeï¼‰====="

# ================================================================
# Phase 0: ç¡®ä¿ git å·²å®‰è£…
# ================================================================
echo "===== Phase 0: ç¡®ä¿ git å·²å®‰è£… ====="
which git || (sudo apt update && sudo apt install -y git)

# ================================================================
# Phase 1: æ›´æ–° GitHub ä»“åº“
# ================================================================
echo "===== Phase 1: æ›´æ–° GitHub ä»“åº“ ====="
cd "${REPO_DIR}"
if [ -d ".git" ]; then
  git pull origin ${GITHUB_BRANCH} || echo "âš  Git pull failed, continuing..."
fi

# ================================================================
# Phase 2: é€šç”¨åˆå§‹åŒ–
# ================================================================
echo "===== Phase 2: æ‰§è¡Œ all_install.sh ====="
cd "${INSTALL_DIR}"
sudo bash all_install.sh

# ================================================================
# Phase 3: åˆå§‹åŒ– Kubernetes æ§åˆ¶å¹³é¢
# ================================================================
echo "===== Phase 3: æ‰§è¡Œ system.sh ====="
sudo bash system.sh

# ================================================================
# Phase 4: é›†ç¾¤åŸºç¡€è®¾æ–½ + GPU Bootstrap
# ================================================================
echo "===== Phase 4: é›†ç¾¤åŸºç¡€è®¾æ–½ + GPU Bootstrap ====="

# ------------------------------------------------
# Step 0: NVIDIA Device Plugin
# ------------------------------------------------
echo "===== Step 0: Install NVIDIA Device Plugin ====="

if [ -f "${CONTROL_DIR}/config/k8s/system/nvidia-device-plugin.yaml" ]; then
  kubectl apply -f "${CONTROL_DIR}/config/k8s/system/nvidia-device-plugin.yaml"
elif [ -f "${REPO_DIR}/script/nvidia-device-plugin.yaml" ]; then
  kubectl apply -f "${REPO_DIR}/script/nvidia-device-plugin.yaml"
else
  echo "âŒ nvidia-device-plugin.yaml not found"
  exit 1
fi

echo ">>> Waiting for NVIDIA device plugin to be ready..."
kubectl rollout status ds/nvidia-device-plugin-daemonset -n kube-system --timeout=60s || \
  echo "âš  Device plugin rollout may still be in progress, continuing..."
sleep 2
kubectl describe node system | grep -A4 nvidia.com/gpu || \
  echo "âš  GPU not visible yet, continue..."

# ------------------------------------------------
# Step 0.5: Ensure NVIDIA RuntimeClass (CRITICAL)
# ------------------------------------------------
echo "===== Step 0.5: Ensure NVIDIA RuntimeClass ====="

RUNTIMECLASS_YAML="${CONTROL_DIR}/config/k8s/system/runtimeclass-nvidia.yaml"

if [ -f "${RUNTIMECLASS_YAML}" ]; then
  kubectl get runtimeclass nvidia >/dev/null 2>&1 || \
    kubectl apply -f "${RUNTIMECLASS_YAML}"
  echo "âœ” RuntimeClass nvidia created/verified from ${RUNTIMECLASS_YAML}"
else
  echo ">>> runtimeclass-nvidia.yaml not found, creating inline..."
  cat <<EOF | kubectl apply -f -
apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: nvidia
handler: nvidia
EOF
fi

kubectl get runtimeclass nvidia
echo ">>> RuntimeClass nvidia details:"
kubectl get runtimeclass nvidia -o yaml | grep -A2 "handler:"

# ------------------------------------------------
# Step 1: Namespaces / Node labels
# ------------------------------------------------
cd "${CONTROL_DIR}"

kubectl apply -f config/k8s/base/namespaces/

SYSTEM_NODE="system"
kubectl label node ${SYSTEM_NODE} system=true ingress=true gpu-node=true --overwrite

# ------------------------------------------------
# Step 2: ingress-nginx
# ------------------------------------------------
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx || true
helm repo update

helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
  --namespace ingress-nginx \
  --create-namespace \
  --set controller.hostNetwork=true \
  --set controller.dnsPolicy=ClusterFirstWithHostNet \
  --set controller.service.type=ClusterIP

# ------------------------------------------------
# Step 3: ArgoCD
# ------------------------------------------------
kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
sleep 15
kubectl apply -f config/k8s/argocd/argocd-ingress.yaml

kubectl apply -f config/k8s/argocd/base-application.yaml
kubectl apply -f config/k8s/argocd/llm-application.yaml
kubectl apply -f config/k8s/argocd/monitoring-application.yaml
kubectl apply -f config/k8s/argocd/argocd-ingress-application.yaml

# ------------------------------------------------
# Step 3.5: ArgoCD Image Updater
# ------------------------------------------------
echo "===== Step 3.5: Install ArgoCD Image Updater ====="

# åˆ›å»ºå¿…è¦çš„ Secretï¼ˆGit å†™å›å‡­è¯å’Œ Docker Registry è®¤è¯ï¼‰
echo ">>> Creating Image Updater secrets..."
kubectl apply -f config/k8s/argocd/image-updater/git-credentials-secret.yaml
kubectl apply -f config/k8s/argocd/image-updater/docker-registry-secret.yaml

# å®‰è£… ArgoCD Image Updaterï¼ˆä½¿ç”¨ Helmï¼‰
echo ">>> Installing ArgoCD Image Updater via Helm..."
helm repo add argo https://argoproj.github.io/argo-helm || true
helm repo update

helm upgrade --install argocd-image-updater argo/argocd-image-updater \
  --namespace argocd \
  --create-namespace \
  -f config/k8s/argocd/image-updater/values.yaml \
  --wait --timeout=5m || echo "âš  Image Updater installation may still be in progress..."

echo ">>> Waiting for Image Updater to be ready..."
sleep 10
kubectl get pods -n argocd | grep image-updater || echo "âš  Image Updater pods may still be starting..."

# ------------------------------------------------
# Step 4: çŠ¶æ€æ£€æŸ¥
# ------------------------------------------------
kubectl get runtimeclass
kubectl get nodes -o wide
kubectl get pods -A -o wide

echo ""
echo "ğŸ‰ GPU-ready Kubernetes cluster bootstrap å®Œæˆ"