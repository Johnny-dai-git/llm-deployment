#!/bin/bash
set -e

# ======= ÈÖçÁΩÆÂå∫Âüü =======
GITHUB_USERNAME="Johnny-dai-git"
GITHUB_TOKEN="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"
GITHUB_REPO="llm-deployment"
GITHUB_BRANCH="main"
GITHUB_URL="https://${GITHUB_TOKEN}@github.com/${GITHUB_USERNAME}/${GITHUB_REPO}.git"

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPO_DIR="${SCRIPT_DIR}"
INSTALL_DIR="${REPO_DIR}/install"
CONTROL_DIR="${REPO_DIR}/control"

echo "===== Êú¨Âú∞ system ËäÇÁÇπÂÆåÊï¥ÂàùÂßãÂåñÂºÄÂßãÔºàcontrol planeÔºâ====="

# ================================================================
# Phase 0: Á°Æ‰øù git Â∑≤ÂÆâË£Ö
# ================================================================
echo "===== Phase 0: Á°Æ‰øù git Â∑≤ÂÆâË£Ö ====="
which git || (sudo apt update && sudo apt install -y git)

# ================================================================
# Phase 1: Êõ¥Êñ∞ GitHub ‰ªìÂ∫ì
# ================================================================
echo "===== Phase 1: Êõ¥Êñ∞ GitHub ‰ªìÂ∫ì ====="
cd "${REPO_DIR}"
if [ -d ".git" ]; then
  git pull origin ${GITHUB_BRANCH} || echo "‚ö† Git pull failed, continuing..."
fi

# ================================================================
# Phase 2: ÈÄöÁî®ÂàùÂßãÂåñ
# ================================================================
echo "===== Phase 2: ÊâßË°å all_install.sh ====="
cd "${INSTALL_DIR}"
sudo bash all_install.sh

# ================================================================
# Phase 3: ÂàùÂßãÂåñ Kubernetes ÊéßÂà∂Âπ≥Èù¢
# ================================================================
echo "===== Phase 3: ÊâßË°å system.sh ====="
sudo bash system.sh

# ================================================================
# Phase 4: ÈõÜÁæ§Âü∫Á°ÄËÆæÊñΩ + GPU Bootstrap
# ================================================================
echo "===== Phase 4: ÈõÜÁæ§Âü∫Á°ÄËÆæÊñΩ + GPU Bootstrap ====="

# ------------------------------------------------
# Step 0: NVIDIA Device Plugin
# ------------------------------------------------
echo "===== Step 0: Install NVIDIA Device Plugin ====="

if [ -f "${CONTROL_DIR}/config/k8s/system/nvidia-device-plugin.yaml" ]; then
  kubectl apply -f "${CONTROL_DIR}/config/k8s/system/nvidia-device-plugin.yaml"
elif [ -f "${REPO_DIR}/script/nvidia-device-plugin.yaml" ]; then
  kubectl apply -f "${REPO_DIR}/script/nvidia-device-plugin.yaml"
else
  echo "‚ùå nvidia-device-plugin.yaml not found"
  exit 1
fi

echo ">>> Waiting for NVIDIA device plugin to be ready..."
kubectl rollout status ds/nvidia-device-plugin-daemonset -n kube-system --timeout=60s || \
  echo "‚ö† Device plugin rollout may still be in progress, continuing..."
sleep 2
kubectl describe node system | grep -A4 nvidia.com/gpu || \
  echo "‚ö† GPU not visible yet, continue..."

# ------------------------------------------------
# Step 0.5: Ensure NVIDIA RuntimeClass (CRITICAL)
# ------------------------------------------------
echo "===== Step 0.5: Ensure NVIDIA RuntimeClass ====="

RUNTIMECLASS_YAML="${CONTROL_DIR}/config/k8s/system/runtimeclass-nvidia.yaml"

if [ -f "${RUNTIMECLASS_YAML}" ]; then
  kubectl get runtimeclass nvidia >/dev/null 2>&1 || \
    kubectl apply -f "${RUNTIMECLASS_YAML}"
  echo "‚úî RuntimeClass nvidia created/verified from ${RUNTIMECLASS_YAML}"
else
  echo ">>> runtimeclass-nvidia.yaml not found, creating inline..."
  cat <<EOF | kubectl apply -f -
apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: nvidia
handler: nvidia
EOF
fi

kubectl get runtimeclass nvidia
echo ">>> RuntimeClass nvidia details:"
kubectl get runtimeclass nvidia -o yaml | grep -A2 "handler:"

# ------------------------------------------------
# Step 1: Namespaces / Node labels
# ------------------------------------------------
cd "${CONTROL_DIR}"

kubectl apply -f config/k8s/base/namespaces/

SYSTEM_NODE="system"
kubectl label node ${SYSTEM_NODE} system=true ingress=true gpu-node=true --overwrite

# ------------------------------------------------
# Step 2: ingress-nginx
# ------------------------------------------------
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx || true
helm repo update

helm upgrade --install ingress-nginx ingress-nginx/ingress-nginx \
  --namespace ingress-nginx \
  --create-namespace \
  --set controller.hostNetwork=true \
  --set controller.dnsPolicy=ClusterFirstWithHostNet \
  --set controller.service.type=ClusterIP

# ------------------------------------------------
# Step 3: ArgoCD
# ------------------------------------------------
kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
sleep 15
kubectl apply -f config/k8s/argocd/argocd-ingress.yaml

kubectl apply -f config/k8s/argocd/base-application.yaml
kubectl apply -f config/k8s/argocd/llm-application.yaml
kubectl apply -f config/k8s/argocd/monitoring-application.yaml
kubectl apply -f config/k8s/argocd/argocd-ingress-application.yaml

# ------------------------------------------------
# Step 4: Áä∂ÊÄÅÊ£ÄÊü•
# ------------------------------------------------
kubectl get runtimeclass
kubectl get nodes -o wide
kubectl get pods -A -o wide

echo ""
echo "üéâ GPU-ready Kubernetes cluster bootstrap ÂÆåÊàê"