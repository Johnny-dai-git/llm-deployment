apiVersion: apps/v1
kind: Deployment
metadata:
  name: router
  namespace: llm
  labels:
    app: router
  annotations:
    # ArgoCD Image Updater configuration
    argocd-image-updater.argoproj.io/image-list: router=ghcr.io/johnny-dai-git/llm-deployment/router
    argocd-image-updater.argoproj.io/router.update-strategy: name
    argocd-image-updater.argoproj.io/router.allow-tags: regexp:^v-[0-9]{8}-[0-9]{6}$
    argocd-image-updater.argoproj.io/write-back-method: git:secret:argocd/git-credentials
    argocd-image-updater.argoproj.io/git-branch: main
spec:
  replicas: 2                      # High availability
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: router
  template:
    metadata:
      labels:
        app: router
      annotations:
        # Prometheus scraping annotations
        prometheus.io/scrape: "true"
        prometheus.io/port: "8001"
        prometheus.io/path: "/metrics"
    spec:
      terminationGracePeriodSeconds: 60
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      nodeSelector:
        system: "true"
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - router
                topologyKey: kubernetes.io/hostname
      containers:
        - name: router
          image: ghcr.io/johnny-dai-git/llm-deployment/router:latest
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: false
            capabilities:
              drop:
              - ALL

          ports:
            - name: http
              containerPort: 8001              # Router internal HTTP server
              protocol: TCP

          env:
            # vLLM Worker Service
            - name: VLLM_WORKER_HOST
              value: "vllm-worker-service.llm.svc.cluster.local"
            - name: VLLM_WORKER_PORT
              value: "8002"

            # TensorRT-LLM Worker Service
            - name: TRT_WORKER_HOST
              value: "trt-worker-service.llm.svc.cluster.local"
            - name: TRT_WORKER_PORT
              value: "8003"

            # Logging / Mode
            - name: LOG_LEVEL
              value: "info"

            # Default routing policy
            - name: ROUTING_POLICY
              value: "round_robin"
              # Options you can extend later: "least_load", "latency", "weighted", etc.

          # Router becomes ready AFTER internal table / cache is created
          readinessProbe:
            httpGet:
              path: /health
              port: 8001
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3

          # Detect router crash (especially in multi-thread scenarios)
          livenessProbe:
            httpGet:
              path: /health
              port: 8001
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 3

          # Router is CPU-bound (API routing), no GPU needed
          resources:
            requests:
              cpu: "500m"
              memory: "512Mi"
            limits:
              cpu: "2"
              memory: "1Gi"
